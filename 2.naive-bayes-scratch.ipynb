{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive-Bayes-Classifier-Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "class NaiveBayesClassifierScratch:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.class_probs = {}\n",
    "        self.discrete_probs = {}\n",
    "        self.continuous_meta = {}\n",
    "    \n",
    "    def get_discrete_probs(self,i,j,discrete_col_vals,col_vals):\n",
    "        probs_dict = {}\n",
    "        for val in discrete_col_vals:\n",
    "            probs_dict[f'{i}_{j}_{val}'] = sum([1 if j==val else 0 for j in col_vals])/len(col_vals)\n",
    "        return probs_dict\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        unique_y = list(set(y))\n",
    "        \n",
    "        # Separating continuous and discrete (if Unique values < 10% of number of rows -> Discrete(Assumption))\n",
    "        discrete_cols = {}\n",
    "        continuous_cols = []\n",
    "        for i in range(X.shape[1]):\n",
    "            unique_vals = list(set(X[:,i]))\n",
    "            if(len(unique_vals) < 0.1*len(y)):\n",
    "                discrete_cols[i] = unique_vals\n",
    "            else:\n",
    "                continuous_cols.append(i)\n",
    "        self.discrete_cols = discrete_cols.keys()\n",
    "        self.continuous_cols = continuous_cols\n",
    "        for i in unique_y:\n",
    "            self.class_probs[i] = sum([1 if j==i else 0 for j in y])/len(y)\n",
    "            \n",
    "            sub_X = X[[ind for ind,j in enumerate(y) if j==i],:]\n",
    "            n_rows = sub_X.shape[0]\n",
    "            n_cols = sub_X.shape[1]\n",
    "            for j in range(n_cols):\n",
    "                if(j in discrete_cols.keys()):\n",
    "                    self.discrete_probs = self.discrete_probs | self.get_discrete_probs(i,j,discrete_cols[j],sub_X[:,j])\n",
    "                else:\n",
    "                    self.continuous_meta = self.continuous_meta | {f'{i}_{j}': {'mean': np.mean(sub_X[:,j]),'std': np.std(sub_X[:,j])}}\n",
    "    \n",
    "    def predict(self,X):\n",
    "        X = np.array(X)\n",
    "        preds = []\n",
    "        for item in X:\n",
    "            probs = {}\n",
    "            for cls in self.class_probs.keys():\n",
    "                prob = self.class_probs[cls]\n",
    "                for ind,val in enumerate(item):\n",
    "                    if(ind in self.discrete_cols):\n",
    "                        prob *= self.discrete_probs[f'{cls}_{ind}_{val}']\n",
    "                    else:\n",
    "                        ## Normal Distribution\n",
    "                        meta_data = self.continuous_meta[f'{cls}_{ind}']\n",
    "                        prob *= norm.pdf(val,meta_data['mean'],meta_data['std'])\n",
    "                probs[cls] = prob\n",
    "            preds.append(max(probs, key=probs.get))\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayesClassifierScratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['data']\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
